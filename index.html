<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Archit Jain</title>

    <meta name="author" content="Archit Jain">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- INTRODUCTION -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:65%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Archit Jain
                </p>
                <p>I'm an incoming Fall '25 Master's student (<a href="https://www.me.washington.edu/">MechE</a>) at the <a href="https://www.washington.edu/">University of Washington</a>.</p>
                <p>I build robotic systems that reason, adapt, and act in the messy real world — solving non-trivial problems in dynamic environments. My interests lie at the intersection of autonomy, control, and learning, with a particular excitement for robots that move through space (mobile robots, quadrupeds, arms-on-wheels) and make sense of it along the way.</p>
                <p>Currently, I'm a Robotics Engineer at <a href="https://www.bharatforge.com/">Kalyani Group</a>, developing autonomy stacks for quadrupeds and humanoids — from perception pipelines to real-time control and multi-robot communication systems. Before this, I spent a year at the <a href="https://www.e-yantra.org/">ERTS Lab</a>, <a href="https://www.cse.iitb.ac.in/research/labs">IIT Bombay</a>, as a Project Assistant under <a href="https://scholar.google.co.in/citations?user=Qz7H0U0AAAAJ&hl=en">Prof. Kavi Arya</a>, where I worked on lightweight grasping algorithms and an integrated mobile manipulation system for automated warehouse tasks. I also led nationwide training in robotics and embedded systems for over 100 faculty and 1300+ students, reinforcing my commitment to accessible robotics education.</p>
                <p>I bring a grounded engineering background (Bachelor of Technology in Production Engineering from <a href="https://www.vit.edu/">VIT Pune</a>) and got my start in robotics by building and breaking things — custom actuators, humanoids with 3D-printed joints, drone middleware for BVLOS operations. Some of these led to podium finishes at the <a href="https://www.sih.gov.in/sih2022s">Smart India Hackathon</a> and <a href="https://en.wikipedia.org/wiki/ABU_Robocon#ABU_Robocon_2022">ABU Robocon</a>; others ended in flying gears and burned stepper motors (equal learning on both ends).</p>
                <p style="text-align:center">
                  <a href="mailto:arrchit.jain@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/ArchitJain-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/architjain-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=c0ZiHpkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/anujjain-dev/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/archit-jain19/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:35%;max-width:35%">
                <a href="images/architjain-profile-3.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/architjain-profile-3.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- NEWS -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody><tr>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <style>
                  .ni {
                    vertical-align: top;
                    padding: 5px;
                  }
                  .nd {
                    vertical-align: top;
                    padding: 5px;
                    font-weight: bold;
                  }
                </style>
                <h2>News</h2>
                <p>
                </p><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding:10px;vertical-align:top;">
                  <tbody><tr>
                    <td class="nd">10/2024</td>
                    <td class="ni">"Scalable and Low-Cost Remote Lab Platforms: Teaching Industrial Robotics Using Open-Source Tools and Understanding Its Social Implications" is <span style="font-weight:bold;color:green">accepted at</span> ICSR - 2024 (International Conference on Social Robotics - Denmark 2024)</td>
                  </tr>
                  <tr>
                    <td class="nd">06/2023</td>
                    <td class="ni">Received Project Assistantship at Embedded Real-Time Systems Laboratory, IIT Bombay under Prof. Kavi Arya</td>
                  </tr>
                  <tr>
                    <td class="nd">09/2022</td>
                    <td class="ni">Secured 1st Rank at the "Smart India Hackathon - Hardware Edition 2022", organized nationwide by the Ministry of Education, Government of India.</td>
                  </tr>
                  <tr>
                    <td class="nd">07/2022</td>
                    <td class="ni">Awarded "Best Software" at ABU Robocon India 2022 (DD National), held at IIT Delhi</td>
                  </tr>
                  <tr>
                    <td class="nd">07/2022</td>
                    <td class="ni">Achieved Rank 5 at ABU Robocon India 2022 (DD National), held at IIT Delhi - a national robotics contest among engineering institutions</td>
                  </tr>
                  <tr>
                    <td class="nd">09/2021</td>
                    <td class="ni">"Certified SolidWorks Additive Manufacturing Associate" by Dassault Systemes</td>
                  </tr>
                  <!-- <tr>
                    <td class="nd">04/2021</td>
                    <td class="ni">Runner-up at "OnSpot Hackathon" held at NIT Durgapur</td>
                  </tr>
                  <tr>
                    <td class="nd">10/2020</td>
                    <td class="ni">"Certified SolidEdge Associate II" by Siemens</td>
                  </tr>
                  <tr>
                    <td class="nd">05/2020</td>
                    <td class="ni">"Certified SolidEdge Associate I" by Siemens</td>
                  </tr> -->
                </tbody></table>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <!-- RESEARCH -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody><tr>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                I am interested in how robots perceive and navigate complex, unfamiliar 3D environments.
                While humans effortlessly make sense of cluttered scenes, uneven terrain, and dynamic obstacles — often with partial information — robotic systems still struggle to match this adaptability.
                What representations, feature identifications and system architectures allow robots to extract actionable understanding from noisy, incomplete data?
                How can physical interaction and perception be tightly coupled so that robots can not only move through the world but reason about it as they go?
                </p>
              </td>
            </tr>
          </tbody></table> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/aahs_awms_intro_combined.png" alt="project image" style="margin-bottom: 12px; width:auto; height:auto; max-width:100%;">
                <img src="images/CL_new.png" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3>Scalable and low-cost remote lab platforms: Teaching industrial robotics using open-source tools and understanding its social implications</h3>
                Amit Kumar, Jaison Jose, <strong>Archit Jain</strong>, Siddharth Kulkarni, Kavi Arya
                <br>
                <em>International Conference on Social Robotics (ICSR)</em>, 2024
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-981-96-3522-1_19">springer</a> /
                <a href="https://arxiv.org/pdf/2412.15369">arXiv</a>
                <p>
                  </p><p>With recent advancements in industrial robots, educating students in new technologies and preparing them for the future is imperative. However, access to industrial robots for teaching poses challenges, such as the high cost of acquiring these robots, the safety of the operator and the robot, and complicated training material. This paper proposes two low-cost platforms built using open-source tools like Robot Operating System (ROS) and its latest version ROS 2 to help students learn and test algorithms on remotely connected industrial robots.
                    <a href="https://arxiv.org/pdf/2412.15369"> [...] </a>
                </p>
              </td>

            </tr>

            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="/images/x1.png" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3>Transferable Reinforcement Learning via Generalized Occupancy Models</h3>
                <br>
                Chuning Zhu, Xinqi Wang, <strong>Tyler Han</strong>, Simon Du, Abhishek Gupta
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
                <br>
                <a href="https://weirdlabuw.github.io/gom/">website</a> /
                <a href="https://github.com/WEIRDLabUW/gom">code</a> /
                <a href="https://arxiv.org/abs/2403.06328">arXiv</a>
                <p>
                  </p><p>Intelligent agents must be generalists, capable of quickly adapting to various tasks. In reinforcement learning (RL), model-based RL learns a dynamics model of the world, in principle enabling transfer to arbitrary reward functions through planning. However, autoregressive model rollouts suffer from compounding error, making model-based RL ineffective for long-horizon problems.
                    <a href="https://arxiv.org/abs/2403.06328"> [...] </a>
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="/images/vditch.gif" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3>Model Predictive Control for Aggressive Driving over Uneven Terrain</h3>
                <br>
                <strong>Tyler Han</strong>, Alex Liu, Anqi Li, Alex Spitzer, Guanya Shi, Byron Boots
                <br>
                <em>Robotics: Science &amp; Systems (RSS)</em>, 2024
                <br>
                <a href="https://sites.google.com/cs.washington.edu/off-road-mpc">website</a> /
                <a href="https://arxiv.org/abs/2311.12284.pdf">arXiv</a>              
                <p>
                  </p><p>Terrain traversability in unstructured off-road autonomy has traditionally relied on semantic classification, resource-intensive dynamics models, or purely geometry-based methods to predict vehicle-terrain interactions. While inconsequential at low speeds, uneven terrain subjects our full-scale system to safety-critical challenges at operating speeds of 7–10 m/s. This study focuses particularly on uneven terrain
                    <a href="https://arxiv.org/abs/2311.12284.pdf"> [...] </a>      
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="/images/regime.png" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3>Dynamics Models in the Aggressive Off-Road Driving Regime</h3>
                <br>
                <strong>Tyler Han</strong>, Sidharth Talia, Rohan Panicker, Preet Shah, Neel Jawale, Byron Boots
                <br>
                <em>Workshop on Resilient Off-Road Autonomy, ICRA</em>, 2024
                <br>
                <a href="https://github.com/prl-mushr/BeamNGRL">code</a> /
                <a href="https://arxiv.org/abs/2405.16487">arXiv</a>              
                <p>
                  </p><p>Current developments in autonomous off-road driving are steadily increasing performance through higher speeds and more challenging, unstructured environments. However, this operating regime subjects the vehicle to larger inertial effects, where consideration of higher-order states is necessary to avoid failures such as rollovers or excessive impact forces. Aggressive driving through Model
                    <a href="https://arxiv.org/abs/2405.16487"> [...] </a>
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/prl.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3>Learning Motor Primitives</h3>
                <br>
                <strong>Tyler Han</strong>, Carl Glen Henshaw              
                <br>
                <em>arXiv preprint</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2312.03328">arXiv</a>
                <p>
                  </p><p>In an undergraduate project, I tackled part of the challenge of teaching robots to perform motor skills from a small number of demonstrations. We proposed a novel approach by joining the theories of Koopman Operators and Dynamic Movement Primitives to Learning from Demonstration. Our approach, named Autoencoder Dynamic Mode Decomposition
                    <a href="https://arxiv.org/abs/2312.03328"> [...] </a>      
                </p>
              </td>
            </tr>
          </tbody></table>

<!-- 
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/prl.jpg" alt="prl" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <span class="papertitle">Parallelizing Reinforcement Learning</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                <br>
                <em>Technical Report</em>, 2009
                <br>
                <a href="data/BarronPRL2009.bib">bibtex</a>
                <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 136, 2008
                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>
          </tbody></table> -->



          <!-- Experience -->
          <!-- Education -->
          <!-- Certification -->
          <!-- Achievement -->

          <!-- footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    website adapted from <a href="https://jonbarron.info">here</a> and <a href="https://thanandnow.github.io/">here</a>
                  </p>
                </td>
              </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
