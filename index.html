<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Archit Jain</title>

    <meta name="author" content="Archit Jain">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <!-- INTRODUCTION -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:65%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Archit Jain
                </p>
                <p>I'm an incoming Fall '25 Master's student at the <a href="https://www.washington.edu/">University of Washington</a>.</p>
                <p>I build robotic systems that reason, adapt, and act — solving non-trivial problems in messy real world. My interests lie in autonomy, control, and learning, with a particular excitement for robots that move through space (mobile robots, quadrupeds, humanoids) and make sense of it along the way.</p>
                <p>Currently, I'm working as a Robotics Engineer at <a href="https://www.bharatforge.com/">Kalyani Group</a>, developing autonomy stacks for quadrupeds and humanoids. Before this, I spent a year at the <a href="https://www.e-yantra.org/">ERTS Lab</a>, <a href="https://www.cse.iitb.ac.in/research/labs">IIT Bombay</a>, as a Project Assistant under <a href="https://scholar.google.co.in/citations?user=Qz7H0U0AAAAJ&hl=en">Prof. Kavi Arya</a>.</p>
                <p>I bring a grounded engineering background (Bachelors in Production Engineering from <a href="https://www.vit.edu/">VIT Pune</a>) and got my start in robotics by building and breaking things — custom actuators, humanoids, drone middleware. Some of these led to podium finishes at the <a href="https://www.sih.gov.in/sih2022s">Smart India Hackathon</a> and <a href="https://en.wikipedia.org/wiki/ABU_Robocon#ABU_Robocon_2022">ABU Robocon</a>; others ended in flying gears and burned stepper motors.</p>
                <p>Aside from robotics, I enjoy swimming and hiking. Checkout my <a href="data/architjain-bio.txt">Bio</a> to know more about my past life!</p>
                <p style="text-align:center">
                  <a href="mailto:arrchit.jain@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/ArchitJain-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/architjain-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=c0ZiHpkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/anujjain-dev/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/archit-jain19/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:35%;max-width:35%;text-align: center;">
                <a href="images/architjain-profile-3.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/architjain-profile-3.png" class="hoverZoomLink"></a>
                <!-- <p style="font-size:1.0rem;margin:8px;">Robotics Engineer</p> -->
                <!-- <br> -->
                <!-- <a href="https://www.washington.edu/">Kalyani Group</a> -->
                <!-- <br> -->
                <!-- <email>arrchit.jain (at) gmail.com</email> -->
              </td>
            </tr>
          </tbody></table>

          <!-- NEWS -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody><tr>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <style>
                  .ni {
                    vertical-align: top;
                    padding: 5px;
                  }
                  .nd {
                    vertical-align: top;
                    padding: 5px;
                    font-weight: bold;
                  }
                </style>
                <h2>News</h2>
                <p>
                </p><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding:10px;vertical-align:top;">
                  <tbody><tr>
                    <td class="nd">10/2024</td>
                    <td class="ni">"Scalable and Low-Cost Remote Lab Platforms: Teaching Industrial Robotics Using Open-Source Tools and Understanding Its Social Implications" is <span style="font-weight:bold;color:green">accepted at</span> ICSR - 2024 (International Conference on Social Robotics - Denmark 2024)</td>
                  </tr>
                  <tr>
                    <td class="nd">06/2023</td>
                    <td class="ni">Received Project Assistantship at Embedded Real-Time Systems Laboratory, IIT Bombay under Prof. Kavi Arya</td>
                  </tr>
                  <tr>
                    <td class="nd">09/2022</td>
                    <td class="ni">Secured 1st Rank at the "Smart India Hackathon - Hardware Edition 2022", organized nationwide by the Ministry of Education, Government of India.</td>
                  </tr>
                  <tr>
                    <td class="nd">07/2022</td>
                    <td class="ni">Awarded "Best Software" at ABU Robocon India 2022 (DD National), held at IIT Delhi</td>
                  </tr>
                  <tr>
                    <td class="nd">07/2022</td>
                    <td class="ni">Achieved Rank 5 at ABU Robocon India 2022 (DD National), held at IIT Delhi - a national robotics contest among engineering institutions</td>
                  </tr>
                  <tr>
                    <td class="nd">09/2021</td>
                    <td class="ni">"Certified SolidWorks Additive Manufacturing Associate" by Dassault Systemes</td>
                  </tr>
                  <!-- <tr>
                    <td class="nd">04/2021</td>
                    <td class="ni">Runner-up at "OnSpot Hackathon" held at NIT Durgapur</td>
                  </tr>
                  <tr>
                    <td class="nd">10/2020</td>
                    <td class="ni">"Certified SolidEdge Associate II" by Siemens</td>
                  </tr>
                  <tr>
                    <td class="nd">05/2020</td>
                    <td class="ni">"Certified SolidEdge Associate I" by Siemens</td>
                  </tr> -->
                </tbody></table>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <!-- RESEARCH -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody><tr>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                I am interested in how robots perceive and navigate complex, unfamiliar 3D environments.
                While humans effortlessly make sense of cluttered scenes, uneven terrain, and dynamic obstacles — often with partial information — robotic systems still struggle to match this adaptability.
                What representations, feature identifications and system architectures allow robots to extract actionable understanding from noisy, incomplete data?
                How can physical interaction and perception be tightly coupled so that robots can not only move through the world but reason about it as they go?
                </p>
              </td>
            </tr>
          </tbody></table> 
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <!-- <img src="images/aahs_awms_intro_combined.png" alt="project image" style="margin-bottom: 16px; width:auto; height:auto; max-width:100%;"> -->
                <img src="images/CL_new.png" alt="project image" style="width:auto; height:auto; max-width:100%;">
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3 style="margin: 0px;">Scalable and low-cost remote lab platforms: Teaching industrial robotics using open-source tools and understanding its social implications</h3>
                Amit Kumar, Jaison Jose, <strong>Archit Jain</strong>, Siddharth Kulkarni, Kavi Arya
                <br>
                <em>International Conference on Social Robotics (ICSR)</em>, 2024
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-981-96-3522-1_19">springer</a> /
                <a href="https://arxiv.org/pdf/2412.15369">arXiv</a>
                <p>
                  </p><p>With recent advancements in industrial robots, educating students in new technologies and preparing them for the future is imperative. However, access to industrial robots for teaching poses challenges, such as the high cost of acquiring these robots, the safety of the operator and the robot, and complicated training material. This paper proposes two low-cost platforms built using
                    <a href="https://arxiv.org/pdf/2412.15369"> [...] </a>
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/ecg_setup.png" alt="project image" style="border-radius: 6%; margin-bottom: 16px; width:auto; height:auto; max-width:100%;">
                <!-- <img src="images/haf_estimate.png" alt="project image" style="width:auto; height:auto; max-width:100%;"> -->
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3 style="margin: 0px;">Exploring Algorithm for Grasping Unknown Objects using Two Finger Gripper</h3>
                <strong>Archit Jain</strong>, Gokul M K, Jaison Jose, Ravikumar Chaurasia, Kavi Arya
                <br>
                <em>ERTS Lab, CSE IIT Bombay</em>, 2023
                <br>
                <a href="data/report_eYSIP.pdf">paper</a> /
                <a href="data/poster_eysip.pdf">poster</a>
                <p>
                  </p><p>In a research project at IIT Bombay, the objective was to significantly enhance the grasping capabilities of the two-finger gripper robotic arm (such as the UR5 arm) by leveraging a combination of learning and analytical-based algorithms. The focus is on enabling the arm to effectively grasp and manipulate unknown objects with minimal prior knowledge or specific object information
                    <a href="data/report_eYSIP.pdf"> [...] </a>
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/ktl_2dlidar.png" alt="project image" style="border-radius: 6%; margin-bottom: 16px; width:auto; height:auto; max-width:100%;">
                <!-- <img src="images/haf_estimate.png" alt="project image" style="width:auto; height:auto; max-width:100%;"> -->
              </td>
              <td style="padding:2.5%;width:100%;vertical-align:middle">
                <h3 style="margin: 0px;">Generating 3D Point Cloud Data using 2D LiDAR Sensor with ROS</h3>
                <strong>Archit Jain</strong>, Mihir Trivedi, Deepak Jaiswal
                <br>
                <em>Kalyani Technologies Ltd.</em>, 2022
                <br>
                <a href="data/ktl_3d_scanner.pdf">paper</a> /
                <a href="https://youtu.be/1M_JB6N2U-E">video</a>
                <p>
                  </p><p>In a research project at Kalyani Group, this paper describes an algorithm that performs 3D scanning with the help of 2D Light Detection And Ranging (LiDAR) sensor using Robot Operating System (ROS). Using a 2D 360 degree LiDAR we get a LaserScan data in 2D plane. To convert this 2D LiDAR into 3D scanned point cloud data, an additional physical third axis (Z axis) is used for collecting laserscan data in third dimension
                    <a href="data/ktl_3d_scanner.pdf"> [...] </a>
                </p>
              </td>
            </tr>

          </tbody></table>

          <!-- PROJECTS -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody><tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle">
                <h2>Other Interesting Projects</h2>
                <p>
                I have been working on different robotics projects leading towards autonomy. These projects have been development during my internships, workplace, college and competition times.
                </p>
              </td>
            </tr>
          </tbody></table> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">Real-Time 3D Autonomous Navigation and Interoperable Control Systems for Factory-Deployed Legged and Wheeled Robots</h3>
                <em>Kalyani Group, Pune, IN</em>, 2024-25
                <br>
                <a href="data/bfl_quad.pdf">poster</a> /
                <a href="https://drive.google.com/drive/folders/1gAzWwzMAMD4E9Kug81oc7M7EwKKQj5Cd?usp=sharing">image</a> /
                <a href="images/bfl_quad_video.mp4">video</a> /
                <a href="https://www.canva.com/design/DAGsm6Y7dZU/y5B6oavOUH7cVvRpF9xUUg/view?utm_content=DAGsm6Y7dZU&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h742c19eff7">presentation</a>
                <p style="margin-bottom: 0px;">
                  At Kalyani Group, I have developed full-stack autonomy solutions for ground-based robotic platforms including quadrupeds (unitree go2, b2), humanoids (untiree g1), and customized wheeled mobile robots. My work spans the perception-to-control pipeline, with a focus on real-time autonomy, fleet interoperability, and architecture design for robust communication system. I have developed modular autonomy stack with 3D LiDAR-Inertial Odometry (LIO) mapping & localization, along with multi-terrain navigation for indoor, semi-structured and shop floor factory environments. Built and deployed Hardware Abstraction Layers (HAL) for heterogeneous robotic platforms to ensure portability across actuator/sensor configurations and standardize control interfaces. Designed multi robot communication architecture to connect fleet of robots through a dashboard and enable remote mission dispatch, health monitoring, and state feedback. Additionally, designed a fleet management system capable of multi-robot coordination, monitoring, and remote control — supporting real-time interoperability between multiple ground units in shared environments.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.5% 2.5% 2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/bfl_quad_2.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 0.5% 2.5% 0.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/bfl_quad_3.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/bfl_quad_1.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">Collaborative Mobile Manipulation for Autonomous Warehouse Sorting - eYRC 2023-24 Theme Development</h3>
                Amit Kumar, Jaison Jose, <strong>Archit Jain</strong>, Siddharth Kulkarni, Kavi Arya
                <br>
                <em>eYantra - IIT Bombay, Mumbai, IN</em>, 2023-24
                <br>
                <a href="https://youtu.be/gsHRoDTlpF0">video</a> /
                <a href="https://github.com/eYantra-Robotics-Competition/eYRC-2023_Cosmo_Logistic">code</a> /
                <a href="https://arxiv.org/pdf/2412.15369">arXiv</a>
                <p style="margin-bottom: 0px;">
                  Designed and developed the “Cosmo Logistic” theme for the e-Yantra Robotics Competition (eYRC) 2023-24, conducted by IIT Bombay. The project involved the integration of a mobile robot and a UR5 robotic arm to autonomously sort and prepare packages in a simulated inter-planetary warehouse environment. As the theme developer, I engineered the complete pipeline — from autonomous navigation and object localization to coordinated manipulation. Implemented a ROS 2-based system combining SLAM for localization, the Nav2 stack for navigation, and MoveIt for motion planning and manipulation. The system was first validated in the Gazebo simulator and later deployed on physical hardware at IIT Bombay for end-to-end testing. This theme was designed for national-level deployment, enabling students across India to solve advanced mobile manipulation problems using a realistic robotics stack.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.5% 2.5% 2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/awms_1.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 0.5% 2.5% 0.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/awms_3.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/awms_2.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">Autonomous BVLOS Drone Mission Platform - Middleware Development for Enterprise Drone Software Platform</h3>
                <em>Flytbase Labs, CA, USA</em>, 2023
                <br>
                <a href="https://youtu.be/XpRdJbCDku8?si=PKDP8eB8KGrVabdE">video</a> /
                <a href="https://www.flytbase.com/">website</a>
                <p style="margin-bottom: 0px;">
                  In an internship at FlytBase Labs, I contributed towards the development of an autonomous drone operations platform for Beyond Visual Line of Sight (BVLOS) missions. Focused on designing middleware components deployed on edge devices embedded in drones for reliable long-range, real-time communication and control. Developed micro-services for autonomous waypoint navigation, failsafe execution, and health monitoring, communicating over MQTT and integrated with FlytBase’s cloud platform. Implemented mission planning modules using MAVROS and PX4 APIs, enabling real-time trajectory updates and mission re-routing. Designed robust recovery mechanisms including battery-critical RTL (Return-to-Launch), GPS loss detection, and failsafe state transitions via action servers and service clients. Contributed to the full stack — from on-board firmware interaction to high-level service orchestration — enabling globally accessible drone fleet control for applications in logistics, surveillance, and industrial monitoring.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.5% 2.5% 2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/fb_2.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 0.5% 2.5% 0.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/fb_3.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/fb_1.png" alt="project image" style="border-radius: 6%; width:auto; height:150px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">High-Torque Compact Actuator Design for Robotic Arm Joints</h3>
                <em>Kalyani Technologies, Pune, IN</em>, 2022
                <br>
                <a href="https://youtu.be/0cQYwDZK41I">video</a> /
                <a href="https://drive.google.com/drive/folders/10z1ZSBNVZ54UdT_aBf91UOVrOQy-jPwT?usp=sharing">images</a>
                <p style="margin-bottom: 0px;">
                  Designed and fabricated a compact, high-torque actuator for robotic arms operating under heavy-load conditions. The actuator integrates a NEMA-17 stepper motor coupled with a 10:1 custom gear reduction system, achieving a peak torque output of 42 kg·cm at the elbow joint. The system was optimized for minimal footprint and mechanical efficiency through torque transmission analysis, backlash minimization, and bearing load evaluations. Housing and gear components were modeled in SolidWorks and fabricated using aluminum alloy for strength-to-weight optimization. This actuator provides a modular solution for precision-controlled joint motion in industrial and research-grade robotic manipulators.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.0% 2.5% 2.5%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/robot_actuator_1.png" alt="project image" style="border-radius: 6%; width:auto; height:170px; max-width:100%;">
              </td>
              <td style="padding:2.5% 1.0% 2.5% 1.0%;width:33%;vertical-align:middle;min-width:120px">
                <img src="gif/robot_actuator.gif" alt="project image" style="border-radius: 6%; width:auto; height:170px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.0%;width:33%;vertical-align:middle;min-width:120px">
                <img src="images/robot_actuator_2.png" alt="project image" style="border-radius: 6%; width:auto; height:170px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">Perception-Driven Control Architecture for High-Speed Autonomous Robotics - ABU Robocon 2022</h3>
                <em>The Robotics Forum, VIT Pune, IN</em>, 2022
                <br>
                <a href="data/trf_rc_report.pdf">paper</a> /
                <a href="https://youtu.be/wb66ayasfjU">video</a> /
                <a href="https://drive.google.com/drive/folders/1inKM_E7GlY3vGnRJsvSJH5LMPk24aBpw?usp=sharing">images</a>
                <p style="margin-bottom: 0px;">
                  Designed and developed two semi-autonomous robot systemas, part of the DD National ABU Robocon 2022 Robotics Challenge. The competition theme required multi-robot coordination to complete complex, time-sensitive tasks involving precise navigation, object manipulation, and real-time strategy execution. Led the software architecture for the autonomous robot, focusing on robust low-level motion control, multi-sensor data fusion, and reactive state-based behavior planning. Implemented high-frequency control loops for 3-wheeled omni drives using PID and feedforward velocity control. Integrated encoder and IMU data through a complementary filter for odometry estimation, with fallback localization via vision-based trained object model tracking. Designed finite state machines (FSMs) for task sequencing and time-critical transitions, enabling real-time adaptability during match scenarios with sub-50 ms control latency.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.0% 2.5% 2.5%;width:25%;vertical-align:middle;min-width:120px">
                <img src="images/trf_rc_5.png" alt="project image" style="border-radius: 6%; width:auto; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 1.0% 2.5% 1.0%;width:25%;vertical-align:middle;min-width:120px">
                <img src="images/trf_rc_4.png" alt="project image" style="border-radius: 6%; width:auto; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 1.0% 2.5% 1.0%;width:25%;vertical-align:middle;min-width:120px">
                <img src="images/trf_rc_3.png" alt="project image" style="border-radius: 6%; width:auto; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.0%;width:25%;vertical-align:middle;min-width:120px">
                <img src="images/trf_rc_2.png" alt="project image" style="border-radius: 6%; width:auto; height:180px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle;min-width:120px;">
                <h3 style="margin: 0px;">Compact Actuation and Kinematic Design for Dexterous Humanoid Upper Body Motion</h3>
                <em>Insignia Machining, Pune, IN</em>, 2021
                <br>
                <a href="https://youtu.be/tB9Km45fNQY">video</a> /
                <a href="https://drive.google.com/drive/folders/1H5ovseeD5cdA3QBFSUMKSu8eKfDLarpL?usp=sharing">images</a>
                <p style="margin-bottom: 0px;">
                  Led the mechanical design of a humanoid robot's upper body with a focus on precision actuation and compact form factor. Developed a 2-DOF parallel manipulator for neck movement, capable of ±30° pitch and ±45° yaw with sub-degree repeatability. Designed custom linear actuators for the shoulder joint using a 10:1 gear reduction system. Performed detailed gear train calculations, load analysis, and actuator sizing to ensure smooth motion under varying load conditions. Created fully dimensioned 2D manufacturing drawings using SolidWorks, incorporating GD&T and tolerances within ±0.05 mm for CNC milling and laser-cut profiles. The system was fabricated using aluminum for structural components and PLA for non-load-bearing 3D printed parts. The project aimed to improve humanoid upper body dexterity through optimized actuator placement and precise kinematic control.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:2.5% 1.0% 2.5% 2.5%;width:25%;vertical-align:middle;min-width:120px">
                <img src="gif/hr_full.gif" alt="project image" style="border-radius: 6%; width:180px; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 1.0% 2.5% 1.0%;width:25%;vertical-align:middle;min-width:120px">
                <img src="gif/hr_eye.gif" alt="project image" style="border-radius: 6%; width:180px; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 1.0% 2.5% 1.0%; width:25%;vertical-align:middle;min-width:120px">
                <img src="images/hr_2.jpeg" alt="project image" style="border-radius: 6%; width:180px; height:180px; max-width:100%;">
              </td>
              <td style="padding:2.5% 2.5% 2.5% 1.0%;width:25%;vertical-align:middle;min-width:120px">
                <img src="images/hr_1.jpeg" alt="project image" style="border-radius: 6%; width:180px; height:180px; max-width:100%;">
              </td>
            </tr>
          </tbody></table>

          <!-- Experience -->
          <!-- Education -->
          <!-- Certification -->
          <!-- Achievement -->

          <!-- footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    website adapted from <a href="https://jonbarron.info">here</a>
                  </p>
                </td>
              </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
